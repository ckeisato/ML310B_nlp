{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis on reviews data\n",
    "Kei Sato\n",
    "\n",
    "ML310B - Advanced Machine Learning\n",
    "\n",
    "March 25, 2019\n",
    "\n",
    "\n",
    "We will be using reviews data to develop a sentiment analyzer, such that given a document, the model can predict if the review is positive (sentiment = 1) or negative (sentiment = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive and negative review \n",
      " 1    25000\n",
      "0    25000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data...\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data = pd.read_csv('data/Reviews.csv')\n",
    "\n",
    "print(\"Number of positive and negative review\", '\\n', data[\"sentiment\"].value_counts())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Text Processing\n",
    "The reviews corpus has 5000 reviews and is evenly split between positive and negative reviews, so that it contains 2500 positive and 2500 negative reviews.  Before doing any more data exploration, we process the text using standard techniques.  Much of this code was taken from the Lesson 8 HW assignment.\n",
    "\n",
    "The first step is apply some basic text processing.  This function will transform all the letters to lowercase and replace any punctuation or symbols with spaces.  At this step we will also remove English stop words.  Because this corpus contains some <br \\> HTML elements, we will strip those out from the text as well.  This function will return the words in a tokenized format such each word is an element in an array.  After cleaning the text, lemmatization is applied. \n",
    "\n",
    "I did apply stemming to the dataset, but that produced too many non words and so it has been omitted from the text processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'itself', 'been', 'out', 'having', 'at', 'now', 'll', 'doing', 'into', 'the', 'down', 'both', 'be', 'some', \"isn't\", 'wasn', 'we', \"doesn't\", 'himself', 'theirs', 'same', 'how', \"mustn't\", 'shan', 'or', \"hadn't\", 'couldn', 'few', 'any', 'own', 'them', 'through', 'other', 'these', 'just', 'over', \"should've\", 's', 'ours', 'during', 'those', 'below', 'wouldn', 'who', 'd', \"you've\", 'him', 'o', \"you'll\", 'needn', 'weren', 'have', 'if', 'herself', 'hadn', 'until', 'me', 'such', 'do', 'whom', \"hasn't\", 'too', \"didn't\", 'will', \"won't\", \"mightn't\", 'so', 'it', 'as', \"you're\", 'aren', 'from', 'what', 've', 'very', \"wouldn't\", 'under', 'while', \"wasn't\", 'there', 'then', \"you'd\", 'don', \"she's\", 'isn', \"couldn't\", 'between', 'again', 'with', 'ma', 'in', 'each', 'of', 't', 'her', 'hasn', 'yours', 'nor', 'but', 'off', 'against', 'no', 'was', \"aren't\", 'you', 'didn', 'mightn', \"shouldn't\", \"weren't\", 'yourself', 'myself', 'yourselves', 'mustn', 'his', 'can', 'its', 'm', 'most', 'once', 'should', 'a', 'shouldn', 'themselves', 'i', 'y', 'on', 'after', 'she', 'my', 'for', 'had', 'hers', 'where', 'haven', 'our', 'their', 'not', 'than', 'and', 'ourselves', 'he', 'to', 'am', 'your', 'this', \"it's\", \"don't\", 'an', \"needn't\", 'because', 'were', \"shan't\", \"that'll\", 'why', 'all', 'here', \"haven't\", 'more', 'won', 'further', 'when', 'are', 'which', 're', 'does', 'before', 'being', 'by', 'doesn', 'about', 'has', 'above', 'up', 'only', 'did', 'ain', 'is', 'they', 'that'}\n",
      "{'itself', 'been', 'out', 'having', 'at', 'now', 'll', 'doing', 'into', 'the', 'down', 'both', 'be', 'some', \"isn't\", 'wasn', 'we', \"doesn't\", 'himself', 'theirs', 'same', 'how', \"mustn't\", 'shan', 'or', \"hadn't\", 'couldn', 'few', 'any', 'own', 'them', 'through', 'other', 'these', 'just', 'over', \"should've\", 's', 'ours', 'during', 'those', 'below', 'wouldn', 'who', 'd', \"you've\", 'him', 'o', \"you'll\", 'needn', 'weren', 'have', 'if', 'herself', 'hadn', 'until', 'me', 'such', 'do', 'whom', \"hasn't\", 'too', \"didn't\", 'will', \"won't\", \"mightn't\", 'so', 'it', 'as', \"you're\", 'aren', 'from', 'what', 've', 'very', \"wouldn't\", 'under', 'while', \"wasn't\", 'there', 'then', \"you'd\", 'don', \"she's\", 'isn', \"couldn't\", 'between', 'again', 'with', 'ma', 'in', 'each', 'of', 't', 'her', 'hasn', 'yours', 'nor', 'off', 'against', 'no', 'was', \"aren't\", 'you', 'didn', 'mightn', \"shouldn't\", \"weren't\", 'yourself', 'myself', 'yourselves', 'mustn', 'his', 'can', 'its', 'm', 'most', 'once', 'should', 'a', 'shouldn', 'themselves', 'i', 'y', 'on', 'after', 'she', 'my', 'for', 'had', 'hers', 'where', 'haven', 'our', 'their', 'not', 'than', 'and', 'ourselves', 'he', 'to', 'am', 'your', 'this', \"it's\", \"don't\", 'an', \"needn't\", 'because', 'were', \"shan't\", \"that'll\", 'why', 'all', 'here', \"haven't\", 'more', 'won', 'further', 'when', 'are', 'which', 're', 'does', 'before', 'being', 'by', 'doesn', 'about', 'has', 'above', 'up', 'only', 'did', 'ain', 'is', 'they', 'that'}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'but'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-4d875ca52a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m test_data[\"review\"] = test_data[\"review\"].apply(lambda text:\n\u001b[0m\u001b[1;32m     44\u001b[0m                                                 combine_tokened_words(\n\u001b[1;32m     45\u001b[0m                                                 text_lemmatization(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-4d875ca52a8a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     44\u001b[0m                                                 combine_tokened_words(\n\u001b[1;32m     45\u001b[0m                                                 text_lemmatization(\n\u001b[0;32m---> 46\u001b[0;31m                                                 text_processing(text))))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-4d875ca52a8a>\u001b[0m in \u001b[0;36mtext_processing\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# filtered_sentence contain all words that are not in stopwords dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mstop_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'but'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mfiltered_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_word\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfiltered_sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'but'"
     ]
    }
   ],
   "source": [
    "# Taken Lesson 8 HW assignment\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "replace_re_by_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "delete_re_symbols = re.compile('[^0-9a-z #+_]')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.remove('but')\n",
    "\n",
    "def combine_tokened_words(tokened_words):\n",
    "    length_of_string=len(tokened_words)\n",
    "    text_new=\"\"\n",
    "    for w in tokened_words:\n",
    "        if w!=tokened_words[length_of_string-1]:\n",
    "             text_new=text_new+w+\" \" # when w is not the last word so separate by whitespace\n",
    "        else:\n",
    "            text_new=text_new+w\n",
    "    return text_new\n",
    "\n",
    "# converts to lowercase and removes <br />, punctuation, stop words, and numbers\n",
    "def text_processing(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"<br />\", '')\n",
    "    text = re.sub(replace_re_by_space.pattern, ' ', text)\n",
    "    text = re.sub(delete_re_symbols.pattern, '', text)\n",
    "    token_word = word_tokenize(text)\n",
    "    \n",
    "    # filtered_sentence contain all words that are not in stopwords dictionary    \n",
    "    filtered_sentence = [w for w in token_word if not w in stop_words]\n",
    "    return filtered_sentence\n",
    "\n",
    "# Lemmatizes words\n",
    "def text_lemmatization(text):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    text = list(map(lambda word: wordnet_lemmatizer.lemmatize(word), text))\n",
    "    return text\n",
    "\n",
    "\n",
    "test_data = data[:500].copy(deep=True)\n",
    "test_data[\"review\"] = test_data[\"review\"].apply(lambda text:\n",
    "                                                combine_tokened_words(\n",
    "                                                text_lemmatization(\n",
    "                                                text_processing(text))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration\n",
    "Below is some initial data exploration.  We can see that the average length of positive and negative reviews is roughtly the same.  The ten most frequently occuring words are also very similar across between the sets of positive and negative reviews.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word count of negative reviews: 137\n",
      "Average word count of positive reviews: 122\n",
      "\n",
      "\n",
      "Top 10 most common words in negative reviews [('movie', 627), ('film', 427), ('one', 258), ('like', 237), ('get', 177), ('even', 159), ('character', 158), ('good', 156), ('would', 153), ('time', 137)]\n",
      "Top 10 most common words in positive reviews [('movie', 409), ('film', 407), ('one', 268), ('like', 173), ('time', 150), ('character', 140), ('see', 139), ('story', 130), ('well', 122), ('good', 119)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter \n",
    "from functools import reduce\n",
    "\n",
    "# Get average length of reviews\n",
    "def get_avg_length_review(data, sentiment):\n",
    "    relevant_reviews = data.loc[data[\"sentiment\"] == sentiment][\"review\"]\n",
    "    avg_review_length = list(map(lambda review: len(review.split()), relevant_reviews))\n",
    "    return int(np.mean(avg_review_length))\n",
    "print(\"Average word count of negative reviews:\", get_avg_length_review(test_data, 0))\n",
    "print(\"Average word count of positive reviews:\", get_avg_length_review(test_data, 1))\n",
    "\n",
    "# Get 10 most frequently occuring words\n",
    "def get_top_words(data, sentiment):\n",
    "    relevant_reviews = data.loc[data[\"sentiment\"] == sentiment][\"review\"]\n",
    "    all_relevant_reviews = reduce(lambda accum, curr: accum + curr, relevant_reviews)\n",
    "    return Counter(all_relevant_reviews.split()).most_common(10)\n",
    "print('\\n')  \n",
    "print(\"Top 10 most common words in negative reviews\", get_top_words(test_data, 0))\n",
    "print(\"Top 10 most common words in positive reviews\", get_top_words(test_data, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the model and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram range (1, 1)\n",
      "Best params {'degree': 1, 'gamma': 'auto', 'kernel': 'linear'}\n",
      "accuracy 0.6933333333333334\n",
      "FPR: [0.         0.43478261 1.        ]\n",
      "TPR: [0.         0.80246914 1.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCORRECT PREDICTION 1 family normally watch local movie simple reason poorly made lack depth worth timethe trailer nasaan ka man caught attention daughter law daughter took time watch afternoon movie exceeded expectation cinematography good story beautiful acting awesome jericho rosales really good so claudinebarretto fact despised diether ocampo prof effective role never touched moved affected local movie imagine cynic like dabbing eye end movie congratulation star cinema way go jericho claudine\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f1eb96780f2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mrun_model_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-f1eb96780f2e>\u001b[0m in \u001b[0;36mrun_model_cv\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mgraph_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mget_incorrect_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-f1eb96780f2e>\u001b[0m in \u001b[0;36mget_incorrect_preds\u001b[0;34m(data, y_true, y_pred)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_incorrect_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CORRECT PREDICTION\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3118\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def graph_roc(y_true, y_pred):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)\n",
    "    print(\"FPR:\", fpr)\n",
    "    print(\"TPR:\", tpr)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3, label='test')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "def get_incorrect_preds(data, y_true, y_pred):\n",
    "    for i in range(0, len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            print(\"CORRECT PREDICTION\", y_true[i], data[i] )\n",
    "        else:\n",
    "            print(\"INCORRECT PREDICTION\", y_true[i], data[i] )\n",
    "        \n",
    "\n",
    "\n",
    "def run_model_cv(data):   \n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data[\"review\"],\n",
    "        data[\"sentiment\"],\n",
    "        test_size=0.3,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    ngrams = [\n",
    "        (1, 1),\n",
    "        (1, 2),\n",
    "        (1, 3),\n",
    "        (1, 4),\n",
    "        (1, 5)\n",
    "    ]\n",
    "    \n",
    "    for ngram_param in ngrams:\n",
    "        print(\"ngram range\", ngram_param)\n",
    "        tfid_vectorizer = TfidfVectorizer(min_df=4, max_df=0.8, use_idf=True, ngram_range=ngram_param).fit(x_train)\n",
    "        _x_train = tfid_vectorizer.transform(x_train)\n",
    "        _x_test = tfid_vectorizer.transform(x_test)\n",
    "        \n",
    "#         kmeans = KMeans(n_clusters=2, random_state=0).fit(_x_train)\n",
    "#         y_pred = kmeans.predict(_x_test)\n",
    "                \n",
    "        cv_clf = GridSearchCV(\n",
    "                    SVC(),\n",
    "                    [\n",
    "                        {\n",
    "                            \"kernel\": [\"linear\", \"poly\"],\n",
    "                            \"degree\": [1, 2],\n",
    "                            \"gamma\": [\"auto\", \"scale\"]\n",
    "                        }\n",
    "                    ],\n",
    "                    cv=5,\n",
    "                    refit=True\n",
    "                )\n",
    "        cv_clf.fit(_x_train, y_train)\n",
    "        print(\"Best params\", cv_clf.best_params_)\n",
    "        \n",
    "        y_pred = cv_clf.predict(_x_test)\n",
    "        print(\"accuracy\", metrics.accuracy_score(y_test, y_pred))\n",
    "        graph_roc(y_test, y_pred)\n",
    "        get_incorrect_preds(x_test, y_test, y_pred)\n",
    "\n",
    "\n",
    "    \n",
    "run_model_cv(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
