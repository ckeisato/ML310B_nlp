{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis on reviews data\n",
    "Kei Sato\n",
    "\n",
    "ML310B - Advanced Machine Learning\n",
    "\n",
    "March 25, 2019\n",
    "\n",
    "#### Project overview\n",
    "For this assignment, we want to use sentiment analysis to predict the polarity of a given film review.  To build the model, we are given a corpus of 50K reviews, each associated with a score of 0 or 1, which respectively indicate that the review is negative or positive.  \n",
    "\n",
    "#### Metrics used\n",
    "We will use accuracy as the main metric used to determine if the model is successful.  But, throughout the model training and cross validation, the proportion of false positives for both classes will be monitored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive and negative reviews \n",
      " 1    25000\n",
      "0    25000\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My family and I normally do not watch local mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Believe it or not, this was at one time the wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>After some internet surfing, I found the \"Home...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One of the most unheralded great works of anim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  My family and I normally do not watch local mo...          1\n",
       "1  Believe it or not, this was at one time the wo...          0\n",
       "2  After some internet surfing, I found the \"Home...          0\n",
       "3  One of the most unheralded great works of anim...          1\n",
       "4  It was the Sixties, and anyone with long hair ...          0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data...\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "data = pd.read_csv('resources/Reviews.csv')\n",
    "print(\"Number of positive and negative reviews\", '\\n', data[\"sentiment\"].value_counts())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove HTML tags\n",
    "Original sentence:\n",
    "```\n",
    "<br /><br />The trailer of \"\"Nasaan ka man\"\" caught my attention, my daughter in law's and daughter's so we took time out to watch it this afternoon.\n",
    "```\n",
    "\n",
    "Removed HTML tags:\n",
    "```\n",
    "The trailer of \"\"Nasaan ka man\"\" caught my attention, my daughter in law's and daughter's so we took time out to watch it this afternoon.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# takes string, returns string\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text)\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert all text to lowercase\n",
    "Original sentence:\n",
    "```\n",
    "The trailer of \"\"Nasaan ka man\"\" caught my attention, my daughter in law's and daughter's so we took time out to watch it this afternoon.\n",
    "```\n",
    "Lowercase:\n",
    "```\n",
    "the trailer of nasaan ka man caught my attention, my daughter in law's and daughter's so we took time out to watch it this afternoon.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes string, returns string\n",
    "def lowercase(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand contractions\n",
    "Original text:\n",
    "```\n",
    "The SF premise isn't unique (although it pretty much was back then)\n",
    "```\n",
    "\n",
    "Without contractions:\n",
    "```\n",
    "The SF premise is not unique (although it pretty much was back then)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tag\n",
    "import json\n",
    "\n",
    "with open('resources/contractions.json', 'r') as f:\n",
    "    contractions = json.load(f)\n",
    "contractions_keys = contractions.keys()\n",
    "\n",
    "# takes tokenized text, returns tokenized text\n",
    "def expand_contractions(text):\n",
    "    return list(map(lambda word: contractions[word] if word in contractions_keys else word, text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove symbols and punctuation\n",
    "Original text:\n",
    "```\n",
    "though it makes the most sophisticated use of the \"\"cut-out\"\" method of animation (a la \"\"south sark\"\"), the real talent behind\n",
    "```\n",
    "Removed symbols and punctuation:\n",
    "```\n",
    "though it makes the most sophisticated use of the cutout method of animation a la south park the real talent behind\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "replace_re_by_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "delete_re_symbols = re.compile('[^0-9a-z #+_]')\n",
    "\n",
    "def remove_symbols_punctuation(text):\n",
    "    text = re.sub(delete_re_symbols.pattern, ' ', text)\n",
    "    text = re.sub(replace_re_by_space.pattern, ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stop words\n",
    "Original text:\n",
    "```\n",
    "I went to this movie tonight with a few friends not knowing more than the Actors that were in it, and that it was supposed to be a horror movie.\n",
    "```\n",
    "Removed stop words:\n",
    "```\n",
    "I went movie tonight friends knowing Actors , supposed horror movie\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    filtered_sentence = [w for w in text if not w in stop_words]\n",
    "    return filtered_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Lemmatization\n",
    "Original text:\n",
    "```\n",
    "I went to this movie tonight with a few friends not knowing more than the Actors that were in it, and that it was supposed to be a horror movie.\n",
    "```\n",
    "Lemmatization applied:\n",
    "```\n",
    "I went movie tonight friends knowing Actors , supposed horror movie\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def text_lemmatization(text):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    text = list(map(lambda word: wordnet_lemmatizer.lemmatize(word), text))\n",
    "    return text\n",
    "\n",
    "# text = \"women cats pony\"\n",
    "\n",
    "# # print(text.split())\n",
    "# text = word_tokenize(text)\n",
    "# print(text_lemmatization(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Text Processing\n",
    "The reviews corpus has 50,000 reviews and is evenly split between positive and negative reviews, so that it contains 25,000 positive and 25,000 negative reviews.  Before doing any more data exploration, we process the text using standard techniques.  Much of this code was taken from the Lesson 8 HW assignment.\n",
    "\n",
    "The first step is apply some basic text processing, it was done in the following order.\n",
    "1.  Remove proper nouns:  This was done by using the NLTK position tagging functionality to identify proper nouns.\n",
    "2.  Expand contractions\n",
    "3.  Convert all text to lowercase\n",
    "4.  Remove `<br />` characters, this was because the `<br />` HTML tag was present in many reviews.  This part of cleaning the text was specific to this corpus.\n",
    "5.  Remove symbols and punctuation\n",
    "6.  Remove stop words.  For this application, I also removed the words \"movie\" and \"film\" because they were occured very often throughout positive and negative reviews.\n",
    "\n",
    "After cleaning the text, lemmatization is applied.  I did try to apply stemming to the dataset, but that produced too many non words and so it has been omitted from the text processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done processing data\n"
     ]
    }
   ],
   "source": [
    "# Taken Lesson 8 HW assignment\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "import copy\n",
    "# these are only to be run once\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# setting global variables\n",
    "with open('resources/contractions.json', 'r') as f:\n",
    "    contractions = json.load(f)\n",
    "contractions_keys = contractions.keys()\n",
    "\n",
    "replace_re_by_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "delete_re_symbols = re.compile('[^0-9a-z #+_]')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# converts to lowercase and removes <br />, punctuation, stop words, and numbers\n",
    "def text_processing(text):\n",
    "    # remove HTML\n",
    "    text = strip_html(text)\n",
    "    # lower case letters\n",
    "    text = lowercase(text)\n",
    "    # remove punctuation/symbols\n",
    "    text = remove_symbols_punctuation(text)\n",
    "    \n",
    "    # use tokenized text\n",
    "    text = word_tokenize(text)\n",
    "    \n",
    "    # expand contractions\n",
    "    text = expand_contractions(text)\n",
    "    # remove stop words\n",
    "    text = remove_stop_words(text)\n",
    "    # text lemmatization\n",
    "    text = text_lemmatization(text)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "test_data = copy.deepcopy(data.head(1000))\n",
    "# test_data = copy.deepcopy(data)\n",
    "\n",
    "test_data[\"review\"] = test_data[\"review\"].apply(text_processing)\n",
    "\n",
    "print(\"done processing data\")\n",
    "# print(test_data[\"review\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text before:\n",
    "```\n",
    "Well where do I begin my story?? I went to this movie tonight with a few friends not knowing more than the Actors that were in it, and that it was supposed to be a horror movie.<br /><br />Well I figured out within the first 20 minutes, what a poor decision I had made going out seeing this movie. The Plot was crap, and so was the script. The lines were horrible to the point that people in the audience were laughing hysterically.<br /><br />The cast couldn't have been more plastic looking. Even some of the scenes seemed like they should have been made much quicker...like they dragged on for no particular reason. Very poor editing.<br /><br />All in all this movie was a giant waste of time and money. Boo.\n",
    "```\n",
    "#### Text after:\n",
    "```\n",
    "['well', 'begin', 'story', 'went', 'movie', 'tonight', 'friend', 'knowing', 'actor', 'supposed', 'horror', 'moviewell', 'figured', 'within', 'first', '20', 'minute', 'poor', 'decision', 'made', 'going', 'seeing', 'movie', 'plot', 'crap', 'script', 'line', 'horrible', 'point', 'people', 'audience', 'laughing', 'hystericallythe', 'cast', 'couldnt', 'plastic', 'looking', 'even', 'scene', 'seemed', 'like', 'made', 'much', 'quickerlike', 'dragged', 'particular', 'reason', 'poor', 'editingall', 'movie', 'giant', 'waste', 'time', 'money', 'boo']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data exploration\n",
    "Below is some initial data exploration.  We can see that the average length of positive and negative reviews is roughtly the same.  The ten most frequently occuring words are also very similar across between the sets of positive and negative reviews.  I also outputted the ten least commonly occuring words, in part for my own curiosity and to verify that the ten least commonly occuring words were still complete words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length of reviews:\n",
    "Most reviews were around 100 words, as demonstrated in the graph, some reviews were much longer and some much shorter.  The shortest review was 3 words and the longest is 1429."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min review count: 13\n",
      "Max review count: 927\n",
      "Mean review count: 128.63\n",
      "Standard deviation: 100.72427264567365\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "reviews_length = list(map(lambda review: len(review), test_data[\"review\"]))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.hist(reviews_length, bins=100)\n",
    "plt.xlabel('review word count')\n",
    "plt.ylabel('number of reviews')\n",
    "\n",
    "print(\"Min review count:\", min(reviews_length))\n",
    "print(\"Max review count:\", max(reviews_length))\n",
    "print(\"Mean review count:\", np.mean(reviews_length))\n",
    "print(\"Standard deviation:\", np.std(reviews_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commonly occuring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "10 most common words in negative reviews:\n",
      "movie 99\n",
      "film 84\n",
      "one 57\n",
      "like 43\n",
      "get 42\n",
      "good 37\n",
      "really 35\n",
      "time 28\n",
      "even 27\n",
      "plot 27\n",
      "10 least common words in negative reviews:\n",
      "tough 1\n",
      "internet 1\n",
      "surfing 1\n",
      "ioffercom 1\n",
      "received 1\n",
      "burned 1\n",
      "tape 1\n",
      "recorded 1\n",
      "resolution 1\n",
      "rerecorded 1\n",
      "\n",
      "\n",
      "10 most common words in positive reviews:\n",
      "movie 80\n",
      "film 78\n",
      "one 56\n",
      "guy 34\n",
      "like 31\n",
      "time 29\n",
      "really 28\n",
      "much 25\n",
      "best 24\n",
      "character 24\n",
      "10 least common words in positive reviews:\n",
      "simple 1\n",
      "poorly 1\n",
      "timethe 1\n",
      "trailer 1\n",
      "nasaan 1\n",
      "ka 1\n",
      "caught 1\n",
      "law 1\n",
      "took 1\n",
      "afternoon 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter \n",
    "from functools import reduce\n",
    "from operator import itemgetter\n",
    "import heapq\n",
    "\n",
    "# Get 10 most and least frequently occuring words, verify that real words are coming through\n",
    "def get_most_least_common_words(data, sentiment):\n",
    "    relevant_reviews = data.loc[data[\"sentiment\"] == sentiment][\"review\"]\n",
    "    all_relevant_reviews = reduce(lambda accum, curr: accum + curr, relevant_reviews)\n",
    "    counted_words = Counter(all_relevant_reviews)\n",
    "    most_common = counted_words.most_common(10)\n",
    "    least_common = heapq.nsmallest(10, counted_words.items(), key=itemgetter(1))\n",
    "    return most_common, least_common\n",
    "\n",
    "negative_reviews = get_most_least_common_words(test_data[:100], 0)\n",
    "positive_reviews = get_most_least_common_words(test_data[:100], 1)\n",
    "\n",
    "print('\\n')\n",
    "print(\"10 most common words in negative reviews:\")\n",
    "for item in negative_reviews[0]:\n",
    "    print(item[0], item[1])\n",
    "print(\"10 least common words in negative reviews:\")\n",
    "for item in negative_reviews[1]:\n",
    "    print(item[0], item[1])\n",
    "print('\\n')\n",
    "print(\"10 most common words in positive reviews:\")\n",
    "for item in positive_reviews[0]:\n",
    "    print(item[0], item[1])\n",
    "print(\"10 least common words in positive reviews:\")\n",
    "for item in positive_reviews[1]:\n",
    "    print(item[0], item[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methodology\n",
    "The data transformed by using TFIDIF then fed into a Logistic Regression classifier.  I am using a test train split of 30% and 70%.  The model is run with data that is processed with different ngram lengths and minimum document frequency values.  I am also using the SKlearn cross validation module to test different parameters for the Logistic Regression model itself.\n",
    "\n",
    "I chose the Logistic Regression model because this is a supervised learning problem with binary labels.  I also tried running an SVM model but it took too long to run on my machine with the complete dataset.  Using a decision tree was also considered but the dataset seemed too sparse to use that model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-52ca5e97a77c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     clf = LogisticRegression(random_state=0, solver='lbfgs').fit(_x_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mrun_logisticregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-115-52ca5e97a77c>\u001b[0m in \u001b[0;36mrun_logisticregression\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#     _x_train = vectorizer.transform(x_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#     clf = LogisticRegression(random_state=0, solver='lbfgs').fit(_x_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1590\u001b[0m         \"\"\"\n\u001b[1;32m   1591\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1031\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                                tokenize)\n\u001b[1;32m    328\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 329\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def run_logisticregression(data):\n",
    "    data[\"review\"] = list(map(lambda item: print(item), data[\"review\"]))\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data[\"review\"],\n",
    "        data[\"sentiment\"],\n",
    "        test_size=0.3,\n",
    "        random_state=42\n",
    "    )\n",
    "    vectorizer = TfidfVectorizer(preprocessor=None).fit(x_train)\n",
    "#     _x_train = vectorizer.transform(x_train)\n",
    "#     clf = LogisticRegression(random_state=0, solver='lbfgs').fit(_x_train, y_train)\n",
    "\n",
    "run_logisticregression(test_data)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "    \n",
    "def get_incorrect_predictions(data, y_true, y_pred):\n",
    "    predicted_pos = 0\n",
    "    predicted_neg = 0\n",
    "    correct_predictions = 0\n",
    "    incorrect_predictions = pd.DataFrame({'review': [], 'sentiment': []})\n",
    "    for i in range(0, len(y_true)):\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            correct_predictions+=1\n",
    "        else:\n",
    "            incorrect_predictions.loc[len(incorrect_predictions)] = [data[i], y_pred[i]]\n",
    "            if y_pred[i] == 1:\n",
    "                predicted_pos+=1\n",
    "            else:\n",
    "                predicted_neg+=1\n",
    "    print(\"Predicted POSITIVE, actually NEGATIVE\", round(float(predicted_pos)/float(len(y_true)), 3))\n",
    "    print(\"Predicted NEGATIVE, actually POSITIVE\", round(float(predicted_neg)/float(len(y_true)), 3))\n",
    "    print('\\n')\n",
    "    return incorrect_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done fitting the model\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# returns the accuracy\n",
    "def print_metrics(x_test, y_test, y_pred):\n",
    "    acc = round(accuracy_score(y_test, y_pred), 3)\n",
    "#     print(\"Accuracy:\", acc)        \n",
    "#     print(\"AUC Score:\", round(roc_auc_score(y_test, y_pred), 3))\n",
    "\n",
    "#     incorrect_pred = get_incorrect_predictions(list(x_test), list(y_test), y_pred)\n",
    "#     print(\"For incorrectly predicted reviews:\")\n",
    "#     print(\"Most and least common of predicted negative reviews:\", get_most_least_common_words(incorrect_pred, 0))\n",
    "#     print(\"Most and least common of predicted positive reviews:\", get_most_least_common_words(incorrect_pred, 1))\n",
    "    return acc\n",
    "\n",
    "def run_model(data):   \n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data[\"review\"],\n",
    "        data[\"sentiment\"],\n",
    "        test_size=0.3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    \n",
    "    ngram_range = [\n",
    "        (1, 1),\n",
    "        (1, 2),\n",
    "        (2, 2),\n",
    "        (2, 3),\n",
    "        (2, 4),\n",
    "        (3, 4),\n",
    "        (3, 3)\n",
    "    ]\n",
    "    \n",
    "    min_df_range = [\n",
    "        0.0001,\n",
    "        0.00025,\n",
    "        0.0005,\n",
    "        0.001,\n",
    "        0.0025\n",
    "    ]\n",
    "    \n",
    "    accuracy_by_ngram = []\n",
    "    for ngram_param in ngram_range:\n",
    "        accuracy_by_min_df = []\n",
    "        for min_df_param in min_df_range:\n",
    "#             print(\"ngram range and min_df value\", ngram_param, min_df_param)\n",
    "            vectorizer = TfidfVectorizer(max_df=0.9, min_df=min_df_param, ngram_range=ngram_param).fit(x_train)\n",
    "            _x_train = vectorizer.transform(x_train)\n",
    "\n",
    "            # If there are more columns than rows, exit           \n",
    "            if (_x_train.shape[1] < _x_train.shape[0]):\n",
    "                _x_test = vectorizer.transform(x_test)\n",
    "#                 print(\"done vectorizing\")\n",
    "\n",
    "                cv_clf = GridSearchCV(\n",
    "                            LogisticRegression(),\n",
    "                            [\n",
    "                                {\n",
    "                                    \"solver\": [\"sag\", \"saga\"],\n",
    "                                    \"C\": [0.9, 0.95, 0.99],\n",
    "                                    \"max_iter\": [150, 200, 250]\n",
    "                                }\n",
    "                            ],\n",
    "                            cv=5,\n",
    "                            refit=True\n",
    "                        )\n",
    "#                 print(\"fitting the model on dataset with these dimensions\", _x_train.shape)\n",
    "                cv_clf.fit(_x_train, y_train)\n",
    "#                 print(\"Best params:\", cv_clf.best_params_)\n",
    "\n",
    "                y_pred = cv_clf.predict(_x_test)\n",
    "                accuracy = print_metrics(x_test, y_test, y_pred)\n",
    "                accuracy_by_min_df.append(accuracy)\n",
    "            else:\n",
    "                accuracy_by_min_df.append(0)\n",
    "#                 print(\"Too many features, exiting\", _x_train.shape)\n",
    "        accuracy_by_ngram.append({\n",
    "          \"scores\": accuracy_by_min_df,\n",
    "          \"label\": ngram_param\n",
    "        })\n",
    "    return accuracy_by_ngram, min_df_range\n",
    "\n",
    "model_results = run_model_cv(test_data)\n",
    "print(\"done fitting the model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|n-gram|min document freq|accuracy|\n",
    "|------|------|-----|\n",
    "|(1, 1)| 0.0001|0.884|\n",
    "|(1, 1)| 0.00025|0.884|\n",
    "|(1, 1)| 0.0005|0.885|\n",
    "|(1, 1)| 0.001|0.883|\n",
    "|(1, 1)| 0.0025|0.88|\n",
    "|(1, 2)| 0.0001|n/a|\n",
    "|(1, 2)| 0.00025|n/a|\n",
    "|(1, 2)| 0.0005|0.889|\n",
    "|(1, 2)| 0.001|0.887|\n",
    "|(1, 2)| 0.0025|0.883|\n",
    "|(2, 2)| 0.0001|n/a|\n",
    "|(2, 2)| 0.00025|n/a|\n",
    "|(2, 2)| 0.0005|0.816|\n",
    "|(2, 2)| 0.001|0.793|\n",
    "|(2, 2)| 0.0025|0.743|\n",
    "|(2, 3)| 0.0001|n/a|\n",
    "|(2, 3)| 0.00025|n/a|\n",
    "|(2, 3)| 0.0005|0.816|\n",
    "|(2, 3)| 0.001|0.792|\n",
    "|(2, 3)| 0.0025|0.743|\n",
    "|(2, 4)| 0.0001|n/a|\n",
    "|(2, 4)| 0.00025|n/a|\n",
    "|(2, 4)| 0.0005|0.816|\n",
    "|(2, 4)| 0.001|0.792|\n",
    "|(2, 4)| 0.0025|0.743|\n",
    "|(3, 3)| 0.0001|0.675|\n",
    "|(3, 3)| 0.00025|0.633|\n",
    "|(3, 3)| 0.0005|0.585|\n",
    "|(3, 3)| 0.001|0.554|\n",
    "|(3, 3)| 0.0025|0.552|\n",
    "|(3, 4)| 0.0001|0.675|\n",
    "|(3, 4)| 0.00025|0.633|\n",
    "|(3, 4)| 0.0005|0.585|\n",
    "|(3, 4)| 0.001|0.554|\n",
    "|(3, 4)| 0.0025|0.522|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "The resulting graph displays the minimum document frequency against the accuracy, coded by the n-gram value. \n",
    "The accuracy seems unaffected by the n-gram length and goes down when increasing minimum document frequency.  In general, most parameters yield an accuracy between 85% and 89%, there is not a significant difference between the proportion of misclassified positive or negative documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph_accuracy(accuracies, min_dfs):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.gca().set_ylim(bottom=0.5)\n",
    "    for accuracy in accuracies:\n",
    "        plt.scatter(min_dfs, list(accuracy[\"scores\"]), label=accuracy[\"label\"])\n",
    "        plt.xlabel('Minimum document frequency')\n",
    "        plt.ylabel('Accuracy')\n",
    "    plt.legend(bbox_to_anchor=(0, -0.15, 1, 0), loc=\"best\", borderaxespad=0, title=\"n gram\")\n",
    "    return plt.show()\n",
    "\n",
    "graph_accuracy(model_results[0], model_results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "The accuracies were much better for lower n-gram values.  The best results came from using an n-gram range of 1-2 with an accuracy of 88.9% using a minimum document fequency of 0.0005, which was the lowest value tested that did not produce a matrix with more columns than rows.  Performance drops percipitously when the n-gram range is increased to 2-4 or 3, yielding results that are not much better than guessing (considering the class distribution of the given dataset).  The cross validation module often favored a higher value of C for the Logistic Regression model, usually equal to 0.99 or 0.95.  CV only selected a C of 0.9 when the min document frequency was higher, indicating that the cross validation was accounting for overfitting as more data was included.\n",
    "\n",
    "The model also consistently misclassified positive and negative reviews at roughly the same rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "These results indicate that when using Logistic Regression and a dataset of this size, a lower n-gram is preferred and including as many features before degrading model performance is optimal.  This may indicate that the language of the reviews does not have much consistency on a 2-3 word basis or that phrases are used at the same rate within positive and negative reviews.\n",
    "\n",
    "The main challenge with this dataset is its high dimensionality.  While there are 50,000 data points, there are many more features, in this case n-grams, within this corpus.  Cleaning the data can involve many word transformations, as well detecting if a word is mispelled.  Even after the data is cleaned, we have to determine how much the data to use with the model to reduce the large amount of noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further analysis\n",
    "While this model was able to achieve a roughly 90% accuracy across both classes, there are many more ways to improve on this, either by doing more feature engineering or using a more robust model.\n",
    "\n",
    "Different models:  It would be worthwhile to try different models on the dataset.  An SVM would be appropriate because this is a binary classification problem.  However, I am also interested in the effects of measuring document similarity and using that for a clustering model.\n",
    "\n",
    "Word attributes:  There are other qualities of the individual words that could be further processed.  For example, whether or not the average word length of a review is correlated to the sentiment of the review.  Other aspects could include the obscurity and if the words are mispelled.\n",
    "\n",
    "N-grams and phrases:  This implmentation is processing the data into different n-grams, but there could be more analysis done with n-grams.  Such as collecting longer n-grams (3 to 4 words) by sentiment of the review they appear in and weighting those phrases more while training data.\n",
    "\n",
    "Stemming:  I chose not to include stemming because the nltk libraries were producing too many non words, but it would definitely be worthwhile to invest more time into applying stemming correctly.\n",
    "\n",
    "Sentence structure:  The sentence structure used could be indicative of the document's sentiment.  One hypothesis is that negative reviews have more sentences written in the first person, such beginning with \"I think ...\"  We can also explore if positive or negative reviews are correlated with incorrectly or correctly structured sentences.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "NLTK book http://www.nltk.org/book/\n",
    "\n",
    "Blog post on sentiment analysis https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
